# app/core/embedding_manager.py

from typing import List, Union, Optional
import numpy as np
from app.core.config import settings
import logging

# Define a type alias for an embedding
Embedding = List[float] # Or np.ndarray

logger = logging.getLogger(__name__)

class EmbeddingManager:
    """
    Manages the loading of embedding models and generation of text embeddings.
    """
    _instance = None # For singleton pattern, optional
    _model = None
    _model_name: str
    _embedding_dim: Optional[int] = None

    def __new__(cls, *args, **kwargs):
        # Optional: Implement as a singleton so the model is loaded only once.
        if cls._instance is None:
            cls._instance = super(EmbeddingManager, cls).__new__(cls)
            # Initialization that should only happen once can go here
            # However, actual model loading is better in an explicit init or load method
        return cls._instance

    def __init__(self, model_name: Optional[str] = None):
        """
        Initializes the EmbeddingManager.
        The actual model loading is deferred to ensure it's loaded when first needed
        or can be explicitly loaded.

        Args:
            model_name: The name of the sentence-transformer model to use.
                        If None, it will use the one from settings.
        """
        if EmbeddingManager._model is not None and (model_name is None or model_name == EmbeddingManager._model_name):
            # Model already loaded and matches, or no new model specified
            return

        self._model_name = model_name or settings.EMBEDDING_MODEL_NAME
        # Defer actual model loading to a separate method or first use
        # This prevents loading the model on simple import if not needed immediately.
        # self.load_model() # Or call this explicitly when the app starts or first needed

    def load_model(self) -> None:
        """
        Loads the sentence-transformer model.
        This method can be called explicitly at application startup or is called
        internally by methods that require the model.
        """
        if EmbeddingManager._model is not None and EmbeddingManager._model_name == self._model_name:
            logger.debug(f"Embedding model '{self._model_name}' already loaded.")
            return

        try:
            from sentence_transformers import SentenceTransformer
            logger.info(f"Loading embedding model: {self._model_name}...")
            EmbeddingManager._model = SentenceTransformer(self._model_name)
            EmbeddingManager._model_name = self._model_name # Ensure class attribute is set
            # Determine embedding dimension after loading
            dummy_embedding = EmbeddingManager._model.encode(["test sentence"])[0]
            EmbeddingManager._embedding_dim = len(dummy_embedding)
            logger.info(f"Embedding model '{self._model_name}' loaded successfully. Dimension: {EmbeddingManager._embedding_dim}")
        except ImportError:
            logger.error("sentence-transformers package not installed. Please install with 'poetry add sentence-transformers'")
            raise ImportError("sentence-transformers package not found. Please install it.")
        except Exception as e:
            logger.error(f"Failed to load embedding model '{self._model_name}': {e}", exc_info=True)
            EmbeddingManager._model = None # Ensure model is None if loading failed
            EmbeddingManager._embedding_dim = None
            raise

    def _ensure_model_loaded(self):
        """Ensures the model is loaded before use."""
        if EmbeddingManager._model is None or EmbeddingManager._model_name != self._model_name:
            self.load_model()
        if EmbeddingManager._model is None: # Check again if loading failed
             raise RuntimeError(f"Embedding model '{self._model_name}' could not be loaded.")


    def get_embedding_dimension(self) -> int:
        """
        Returns the dimension of the embeddings generated by the loaded model.
        """
        self._ensure_model_loaded()
        if EmbeddingManager._embedding_dim is None:
            # This should ideally not happen if _ensure_model_loaded worked
            logger.warning("Embedding dimension not determined. Attempting to re-calculate.")
            try:
                dummy_embedding = EmbeddingManager._model.encode(["test"])[0] # type: ignore
                EmbeddingManager._embedding_dim = len(dummy_embedding)
            except Exception as e:
                logger.error(f"Could not determine embedding dimension: {e}")
                raise RuntimeError("Failed to determine embedding dimension.") from e
        return EmbeddingManager._embedding_dim


    def generate_embedding(self, text: str) -> Embedding:
        """
        Generates an embedding for a single piece of text.

        Args:
            text: The input text.

        Returns:
            The generated embedding as a list of floats.
        """
        self._ensure_model_loaded()
        try:
            # The model.encode() method returns a numpy array or list of arrays.
            # For a single text, it's usually a single numpy array.
            embedding_np: np.ndarray = EmbeddingManager._model.encode(text, convert_to_numpy=True) # type: ignore
            return embedding_np.tolist()
        except Exception as e:
            logger.error(f"Error generating embedding for text '{text[:50]}...': {e}", exc_info=True)
            raise

    def generate_embeddings(self, texts: List[str]) -> List[Embedding]:
        """
        Generates embeddings for a list of texts.

        Args:
            texts: A list of input texts.

        Returns:
            A list of embeddings, where each embedding is a list of floats.
        """
        self._ensure_model_loaded()
        if not texts:
            return []
        try:
            embeddings_np: np.ndarray = EmbeddingManager._model.encode(texts) # type: ignore
            return [emb.tolist() for emb in embeddings_np]
        except Exception as e:
            logger.error(f"Error generating embeddings for batch of {len(texts)} texts: {e}", exc_info=True)
            raise

# Global instance (optional, can be managed by a factory or DI)
# This creates an instance when the module is first imported, using settings.
# The actual model loading is deferred until needed or explicitly called.
embedding_manager_instance = EmbeddingManager(model_name=settings.EMBEDDING_MODEL_NAME)

def get_embedding_manager() -> EmbeddingManager:
    """
    Factory function/getter for the EmbeddingManager instance.
    Ensures the model is loaded if accessed via this getter.
    """
    # The instance is already created, this function mainly serves as a standard getter
    # and can be a point to ensure model loading if not done elsewhere (e.g., app startup)
    # embedding_manager_instance._ensure_model_loaded() # Uncomment if you want to force load on get
    return embedding_manager_instance


# Example usage (for testing this file directly):
# async def main():
#     print(f"Using embedding model from settings: {settings.EMBEDDING_MODEL_NAME}")
#     manager = get_embedding_manager()
    
#     # Explicitly load model if not done automatically or at startup
#     # manager.load_model() # This will be called by generate_embedding if not already loaded

#     print(f"Embedding dimension: {manager.get_embedding_dimension()}")

#     test_text = "This is a test sentence for embedding."
#     embedding = manager.generate_embedding(test_text)
#     print(f"\nEmbedding for '{test_text}':")
#     print(embedding[:10]) # Print first 10 dimensions
#     print(f"Length of embedding: {len(embedding)}")

#     test_texts = [
#         "First sentence.",
#         "Another piece of text to embed.",
#         "Embedding models are cool."
#     ]
#     embeddings_batch = manager.generate_embeddings(test_texts)
#     print(f"\nEmbeddings for batch ({len(embeddings_batch)} sentences):")
#     for i, emb_b in enumerate(embeddings_batch):
#         print(f"  Sentence {i+1} embedding (first 10 dims): {emb_b[:10]}, length: {len(emb_b)}")

# if __name__ == "__main__":
#     import asyncio
#     # Ensure .env is loaded if there are model-specific settings or SentenceTransformer uses them
#     from dotenv import load_dotenv
#     from pathlib import Path
#     project_root = Path(__file__).resolve().parent.parent.parent
#     env_path = project_root / ".env"
#     if env_path.exists():
#         load_dotenv(dotenv_path=env_path)
#     asyncio.run(main()) # main is not async here, but if it were, this would be how to run it
